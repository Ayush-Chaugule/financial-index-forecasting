{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed6d612",
   "metadata": {},
   "source": [
    "This script performs regression forecasting on financial or economic time series data using Ridge and Lasso models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Prepare Data\n",
    "data_path = \"data/monthly_data.csv\"     # your dataset path\n",
    "target_column = \"Target_Return\"         # change to your target variable\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found in data.\")\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64579fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF Analysis (Multicollinearity)\n",
    "vif_data = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "})\n",
    "print(\"\\nVIF Analysis:\")\n",
    "print(vif_data)\n",
    "\n",
    "high_vif = vif_data[vif_data[\"VIF\"] > 5]\n",
    "if not high_vif.empty:\n",
    "    print(\"\\n High Multicollinearity Found in:\")\n",
    "    print(high_vif)\n",
    "\n",
    "\n",
    "# %% [4] Define Helper Function\n",
    "def evaluate_model(model, name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fit, evaluate, and visualize Ridge/Lasso models.\"\"\"\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    print(f\"Train R²: {train_r2:.4f}\")\n",
    "    print(f\"Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    # Coefficient Plot\n",
    "    coefficients = pd.DataFrame(model.coef_, index=X_train.columns, columns=[\"Coefficient\"])\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=coefficients[\"Coefficient\"], y=coefficients.index, palette=\"coolwarm\")\n",
    "    plt.title(f\"{name} Regression Coefficients\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Actual vs Predicted - Line Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(y_test.values, label=\"Actual\", marker='o')\n",
    "    plt.plot(y_test_pred, label=\"Predicted\", linestyle='--', marker='x')\n",
    "    plt.legend()\n",
    "    plt.title(f\"{name} - Actual vs Predicted (Monthly Return)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Actual vs Predicted - Bar Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.bar(range(min(15, len(y_test))), y_test.iloc[:15], label=\"Actual\", color=\"skyblue\")\n",
    "    plt.bar(range(min(15, len(y_test))), y_test_pred[:15], label=\"Predicted\", \n",
    "            color=\"orange\", alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{name} - Actual vs Predicted (First 15 Observations)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_test.values - y_test_pred\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.scatter(y_test_pred, residuals, edgecolor='k')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(f\"{name} Residual Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Diagnostic Tests\n",
    "    shapiro_test = shapiro(residuals)\n",
    "    bp_test = het_breuschpagan(residuals, sm.add_constant(X_test))\n",
    "    dw_stat = durbin_watson(residuals)\n",
    "\n",
    "    normality = \"Normal\" if shapiro_test.pvalue > 0.05 else \"Not Normal\"\n",
    "    homoskedasticity = \"Homoskedastic\" if bp_test[1] > 0.05 else \"Heteroskedastic\"\n",
    "    autocorr = \"No Strong Autocorrelation\" if 1.5 < dw_stat < 2.5 else \"Possible Autocorrelation\"\n",
    "\n",
    "    print(f\"\\n{name} Diagnostic Tests:\")\n",
    "    print(f\"Shapiro-Wilk p={shapiro_test.pvalue:.4f} → {normality}\")\n",
    "    print(f\"Breusch-Pagan p={bp_test[1]:.4f} → {homoskedasticity}\")\n",
    "    print(f\"Durbin-Watson={dw_stat:.2f} → {autocorr}\")\n",
    "\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(f\"Train R²: {train_r2:.4f} | Test R²: {test_r2:.4f} | RMSE: {test_rmse:.4f}\")\n",
    "    \n",
    "    return train_r2, test_r2, test_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_train_r2, ridge_test_r2, ridge_rmse = evaluate_model(\n",
    "    ridge, \"Ridge\", X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88910a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_train_r2, lasso_test_r2, lasso_rmse = evaluate_model(\n",
    "    lasso, \"Lasso\", X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Comparison Summary\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Ridge\", \"Lasso\"],\n",
    "    \"Train R²\": [ridge_train_r2, lasso_train_r2],\n",
    "    \"Test R²\": [ridge_test_r2, lasso_test_r2],\n",
    "    \"Test RMSE\": [ridge_rmse, lasso_rmse]\n",
    "})\n",
    "print(\"\\n=== Final Model Comparison ===\")\n",
    "print(comparison.round(4).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
