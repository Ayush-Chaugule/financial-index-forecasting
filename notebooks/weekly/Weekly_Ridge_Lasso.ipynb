{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f8a7e8",
   "metadata": {},
   "source": [
    "WEEKLY RIDGE & LASSO REGRESSION FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b15b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d546725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Prepare Data\n",
    "data_path = \"data/weekly_data.csv\"     # <-- Update path here\n",
    "target_column = \"NFTY_Weekly_Return\"   # <-- Replace with your target column\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\" Data Loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "X = df.drop(columns=[target_column], errors=\"ignore\")\n",
    "y = df[target_column]\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity Check (VIF)\n",
    "vif_data = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "})\n",
    "print(\"\\nVIF Analysis (Multicollinearity Check):\")\n",
    "print(vif_data)\n",
    "\n",
    "high_vif = vif_data[vif_data[\"VIF\"] > 5]\n",
    "if not high_vif.empty:\n",
    "    print(\"\\n High VIF Features:\")\n",
    "    print(high_vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper: Model Evaluation & Diagnostics\n",
    "def evaluate_model(model, name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fit, evaluate, and visualize Ridge or Lasso regression.\"\"\"\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    print(f\"Train R²: {train_r2:.4f}\")\n",
    "    print(f\"Test  R²: {test_r2:.4f}\")\n",
    "    print(f\"RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"MAE:  {test_mae:.4f}\")\n",
    "\n",
    "    # Coefficients Plot\n",
    "    coefficients = pd.DataFrame(model.coef_, index=X_train.columns, columns=[\"Coefficient\"]).sort_values(by=\"Coefficient\")\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(x=\"Coefficient\", y=coefficients.index, data=coefficients, palette=\"coolwarm\")\n",
    "    plt.title(f\"{name} - Coefficients Importance\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Actual vs Predicted\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(y_test.values, label=\"Actual\", marker='o')\n",
    "    plt.plot(y_test_pred, label=\"Predicted\", linestyle='--', marker='x')\n",
    "    plt.legend()\n",
    "    plt.title(f\"{name} - Actual vs Predicted (Weekly Returns)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_test.values - y_test_pred\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(y_test_pred, residuals, edgecolor='k', alpha=0.7)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(f\"{name} - Residual Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Diagnostics\n",
    "    shapiro_test = shapiro(residuals)\n",
    "    bp_test = het_breuschpagan(residuals, sm.add_constant(X_test))\n",
    "    dw_stat = durbin_watson(residuals)\n",
    "\n",
    "    print(f\"\\n{name} Diagnostic Tests:\")\n",
    "    print(f\"Normality (Shapiro): p={shapiro_test.pvalue:.4f}\")\n",
    "    print(f\"Homoskedasticity (Breusch–Pagan): p={bp_test[1]:.4f}\")\n",
    "    print(f\"Autocorrelation (Durbin–Watson): {dw_stat:.2f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Train R²\": train_r2,\n",
    "        \"Test R²\": test_r2,\n",
    "        \"RMSE\": test_rmse,\n",
    "        \"MAE\": test_mae,\n",
    "        \"DW\": dw_stat\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_results = evaluate_model(ridge, \"Ridge\", X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1091f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_results = evaluate_model(lasso, \"Lasso\", X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4802e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Comparison Summary\n",
    "comparison = pd.DataFrame([ridge_results, lasso_results])\n",
    "print(\"\\n=== Model Comparison Summary ===\")\n",
    "print(comparison.round(4).to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=comparison.melt(id_vars=\"Model\", value_vars=[\"Test R²\", \"RMSE\"]), \n",
    "            x=\"variable\", y=\"value\", hue=\"Model\", palette=\"Set2\")\n",
    "plt.title(\"Ridge vs Lasso - Performance Comparison\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a11971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next 4-Week Forecast (Ridge)\n",
    "forecast_weeks = 4\n",
    "X_future = X.iloc[[-1]].values\n",
    "future_forecast = []\n",
    "\n",
    "for _ in range(forecast_weeks):\n",
    "    next_pred = ridge.predict(X_future)[0]\n",
    "    future_forecast.append(round(next_pred, 3))\n",
    "    X_future = np.roll(X_future, -1)\n",
    "    X_future[0, -1] = next_pred\n",
    "\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Week\": [f\"Week +{i+1}\" for i in range(forecast_weeks)],\n",
    "    \"Forecast (Ridge)\": future_forecast\n",
    "})\n",
    "print(\"\\nNext 4 Weeks Forecast (Ridge):\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Comparative Forecast (MLR vs Ridge vs Actual)\n",
    "# (For illustrative results — can remove or update manually)\n",
    "example_forecast = pd.DataFrame({\n",
    "    \"Week\": [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\"],\n",
    "    \"MLR Forecast\": [-0.601, 2.061, -0.984, -6.218],\n",
    "    \"Ridge Forecast\": [-0.707, 3.134, 0.325, -4.401],\n",
    "    \"Actual\": [-0.28, 1.70, -0.28, -3.12]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(example_forecast))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, example_forecast[\"MLR Forecast\"], width, label=\"MLR\", color=\"skyblue\")\n",
    "plt.bar(x, example_forecast[\"Ridge Forecast\"], width, label=\"Ridge\", color=\"orange\")\n",
    "plt.bar(x + width, example_forecast[\"Actual\"], width, label=\"Actual\", color=\"green\")\n",
    "\n",
    "plt.xticks(x, example_forecast[\"Week\"])\n",
    "plt.title(\"MLR vs Ridge Forecast vs Actual (Example Month)\")\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ff809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary\n",
    "print(\"\\n===== INTERPRETATION SUMMARY =====\")\n",
    "print(f\"Ridge: Train R²={ridge_results['Train R²']:.4f}, Test R²={ridge_results['Test R²']:.4f}\")\n",
    "print(f\"Lasso: Train R²={lasso_results['Train R²']:.4f}, Test R²={lasso_results['Test R²']:.4f}\")\n",
    "print(f\"Next 4-Week Ridge Forecast:\\n{forecast_df}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
